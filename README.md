Gold vs. S&P 500 Outperformance Prediction

Team 5: Anabella Trias and Anthony Sierra

Predicting 90-day gold outperformance using macroeconomic time-series data (2006‚Äì2024)

üîç Overview

This project builds a binary classification model that predicts whether gold will outperform the S&P 500 over a 90-day horizon, using 18 years of macroeconomic and financial indicators.

The goal is to explore feature engineering, time-series modeling, and evaluation strategies for tactical asset-allocation signals.

‚∏ª

Project Structure

/data               
/notebooks
    01_data_processing.ipynb
    02_eda.ipynb
    03_modeling.ipynb
data_pipeline.py    
README.md
requirements.txt

Data Sources

Combined 11 datasets from Investing.com and FRED (2006‚Äì2024), including:
	‚Ä¢	Gold spot price
	‚Ä¢	S&P 500 index
	‚Ä¢	CPI (inflation)
	‚Ä¢	Crude oil
	‚Ä¢	Federal funds rate
	‚Ä¢	VIX (volatility index)
	‚Ä¢	Treasury yields (2Y, 10Y)
	‚Ä¢	USD index
	‚Ä¢	Labor data
	‚Ä¢	Recession indicators

Final processed dataset: 4,000+ daily observations.

‚∏ª

Problem Definition

Target:
Gold outperforms the S&P 500 over the next 90 days (1 if true, 0 otherwise).

Type:
Binary classification on time-dependent data.

‚∏ª

Feature Engineering

Created 40+ features using pandas and NumPy, including:

Market & Price Features
	‚Ä¢	Daily & rolling returns
	‚Ä¢	30/60/90-day momentum
	‚Ä¢	Rolling means (7/14/30 days)
	‚Ä¢	Rolling volatility
	‚Ä¢	Drawdown metrics

Macroeconomic Indicators
	‚Ä¢	Inflation changes
	‚Ä¢	Yield curve slope
	‚Ä¢	USD strength
	‚Ä¢	Oil price fluctuations
	‚Ä¢	Volatility spikes (VIX)

Target Construction
	‚Ä¢	90-day forward relative return:
gold_future_return - sp500_future_return

‚∏ª

Exploratory Analysis

Key patterns identified:
	‚Ä¢	Gold‚Äôs strongest relative performance spikes align with crisis periods (2008, 2020).
	‚Ä¢	Increasing VIX, falling yields, and USD volatility strongly correlate with gold outperformance.
	‚Ä¢	Distribution shapes vary significantly pre- and post-2013.

‚∏ª

Modeling Approach

Models Evaluated
	‚Ä¢	Logistic Regression (balanced)
	‚Ä¢	Random Forest
	‚Ä¢	XGBoost

Time-Based Split

To prevent leakage:
	‚Ä¢	Train: earlier years
	‚Ä¢	Test: later years

Performance (Best Model)

Logistic Regression (balanced):
	‚Ä¢	ROC AUC: 0.753
	‚Ä¢	Recall: 82.6%
	‚Ä¢	Precision: 59.2%
	‚Ä¢	Prioritizes recall to maximize signal detection in tactical allocation strategies.

‚∏ª

In-Progress Work
	‚Ä¢	Benchmarking with PyCaret to compare automated ML workflows against manual baselines
  ‚Ä¢	Creation of Streamlit/FastAPI dashboard 

‚∏ª

Tech Stack
	‚Ä¢	Python (pandas, NumPy, scikit-learn)
	‚Ä¢	Matplotlib / Seaborn
	‚Ä¢	Jupyter Notebooks
	‚Ä¢	Conda environment
